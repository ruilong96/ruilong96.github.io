<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ruilong Zhuang</title>
    <link>https://ruilong96.github.io/author/ruilong-zhuang/</link>
      <atom:link href="https://ruilong96.github.io/author/ruilong-zhuang/index.xml" rel="self" type="application/rss+xml" />
    <description>Ruilong Zhuang</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>©2020 Ruilong Zhuang</copyright><lastBuildDate>Thu, 19 Nov 2020 09:19:49 -0500</lastBuildDate>
    <image>
      <url>https://ruilong96.github.io/images/icon_hu86e6d267adcc07f71708eaee974e698b_28616_512x512_fill_lanczos_center_2.png</url>
      <title>Ruilong Zhuang</title>
      <link>https://ruilong96.github.io/author/ruilong-zhuang/</link>
    </image>
    
    <item>
      <title>Riiid AIEd Challenge 2020</title>
      <link>https://ruilong96.github.io/project/riiid-challenge-2020/</link>
      <pubDate>Thu, 19 Nov 2020 09:19:49 -0500</pubDate>
      <guid>https://ruilong96.github.io/project/riiid-challenge-2020/</guid>
      <description>&lt;h2 id=&#34;problem-overview&#34;&gt;Problem Overview&lt;/h2&gt;
&lt;p&gt;Riiid Labs, an AI solutions provider delivering creative disruption to the education market, empowers global education players to rethink traditional ways of learning leveraging AI. With a strong belief in equal opportunity in education, Riiid launched an AI tutor based on deep-learning algorithms in 2017 that attracted more than one million South Korean students. This year, the company released EdNet, the world’s largest open database for AI education containing more than 100 million student interactions.&lt;/p&gt;
&lt;p&gt;The challenge is to create algorithms for &amp;ldquo;Knowledge Tracing,&amp;rdquo; the modeling of student knowledge over time. The &lt;strong&gt;goal&lt;/strong&gt; is to accurately predict how students will perform on future interactions. You will pair your machine learning skills using Riiid’s EdNet data.&lt;/p&gt;
&lt;h2 id=&#34;exploratory-data-analysis&#34;&gt;Exploratory Data Analysis&lt;/h2&gt;
&lt;p&gt;For this analysis, Kaggle provides us with a massive dataset containing five anonymized  files, in which of three contains the details about the students&#39; activities online, the details about the questions, and the details about the lectures. The dataset is a time-series data, and the students&#39; data is recorded chronologically relative to their entry to the system.&lt;/p&gt;
&lt;p&gt;To understand the dataset better, I conducted an exploratory analysis which yielded the following observation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;answer_correctly&lt;/code&gt; is not balanced in a way that the answer correctly cases is more than the answer incorrectly cases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;From &lt;code&gt;user_id&lt;/code&gt; distribution plot, most of the users does not have a lot of activities.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We observe that the same long left tail distribution for three categorical variables(&lt;code&gt;user_id&lt;/code&gt;, &lt;code&gt;task_id&lt;/code&gt;, &lt;code&gt;task_container_id&lt;/code&gt;), indicating a lot specific instances or users does not have a lot of occurrences.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As we can see that some distribution plot has a long left tail which is an indicator of outliers because it suggests that some specific users may have very different patterns than the rest of the user.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;timestamp&lt;/code&gt; is correlated with &lt;code&gt;task_container_id&lt;/code&gt; and &lt;code&gt;prior_question_had_explanation&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;content_id&lt;/code&gt; is correlated with &lt;code&gt;content_type_id&lt;/code&gt; showing that they are somehow related.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prior_question_had_explanation&lt;/code&gt; has positive correlation &lt;code&gt;answered_correctly&lt;/code&gt;, implying that the explanation may help the pupils learn better. Together with the correlation with &lt;code&gt;timestamp&lt;/code&gt;, it may indicate that the longer usage of the platform results in better performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More details are presented in this &lt;a href=&#34;./eda-riiid-answer.html&#34;&gt;notebook&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data-prepossessing&#34;&gt;Data Prepossessing&lt;/h2&gt;
&lt;p&gt;Since the training dataset is massive and the computing resource is limited on the Kaggle platform, we need to cross sampling data without losing generality, and the data preparing and cleaning consisted of the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The given timestamp is the time that has elapsed since the user&amp;rsquo;s first event, not the actual time, so I set a random first access time for each user within a certain interval.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Splits the data into training and validation data based on the timestamp. To simulate the learning process, the later part of the data is used for validation data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Isolate the input data and compute the summary transformation (e.g. sum, count) and then Iteratively select the important ones.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To mimic the learning process and handling new users, progressively update the user statistics, such as the correct answer rate, number of question answered.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For NA values, we filled in the average values accordingly based on our summary transformation before, or filled in False for Boolean values.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lastly, convert all variables into numerical variables for LSBM model.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;modeling&#34;&gt;Modeling&lt;/h2&gt;
&lt;h3 id=&#34;lsbm&#34;&gt;LSBM&lt;/h3&gt;
&lt;p&gt;The first method used for knowledge tracing model was the LSBM model due to its interpretability and the computational speed. The hyperparameters are tuned within the model, and cross-validated on the prepared validation data to avoid overfitting.&lt;/p&gt;
&lt;p&gt;The final training&amp;rsquo;s auc is 0.754181, and valid_1&amp;rsquo;s auc is 0.758319.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./f_imp_lsbm.png&#34; alt=&#34;feature_im&#34;&gt;&lt;/p&gt;
&lt;p&gt;To see more detail, please check out &lt;a href=&#34;./lgbm-v2-feature-engineering-riiid-answer.html&#34;&gt;here(html)&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;dnn-in-progress&#34;&gt;DNN (in progress)&lt;/h3&gt;
&lt;p&gt;Since the dataset is a time-series dataset tracing students&#39; knowledge, the deep neural network with its feed forward feature can better approximate students&#39; performance and make prediction. I am planning to use PyTorch to implement this neural net with convolution and pooling layers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A/B Testing Experiment — A Udacity Course Final Project</title>
      <link>https://ruilong96.github.io/project/a-b-testing-udacity/</link>
      <pubDate>Wed, 18 Nov 2020 18:57:17 -0500</pubDate>
      <guid>https://ruilong96.github.io/project/a-b-testing-udacity/</guid>
      <description>&lt;h1 id=&#34;experiment-overview-free-trial-screener&#34;&gt;Experiment Overview: Free Trial Screener&lt;/h1&gt;
&lt;p&gt;At the time of this experiment, Udacity courses currently have two options on the course overview page: &amp;ldquo;start free trial&amp;rdquo;, and &amp;ldquo;access course materials&amp;rdquo;. If the student clicks &amp;ldquo;start free trial&amp;rdquo;, they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first. If the student clicks &amp;ldquo;access course materials&amp;rdquo;, they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback.&lt;/p&gt;
&lt;p&gt;In the experiment, Udacity tested a change where if the student clicked &amp;ldquo;start free trial&amp;rdquo;, they were asked how much time they had available to devote to the course. If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free. At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead. This screenshot shows what the experiment looks like.&lt;/p&gt;
&lt;h1 id=&#34;experiment-setup&#34;&gt;Experiment Setup&lt;/h1&gt;
&lt;p&gt;The &lt;strong&gt;hypothesis&lt;/strong&gt; was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn&amp;rsquo;t have enough time—without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches&#39; capacity to support students who are likely to complete the course.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Null Hypothesis:&lt;/strong&gt;  No significant change and  ineffective in reducing the early Udacity course cancellation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Alternative Hypothesis:&lt;/strong&gt; This reduces the number of frustrated students who left the free trial.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;unit of diversion is a cookie&lt;/strong&gt;, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page.&lt;/p&gt;
&lt;h1 id=&#34;experiment-design&#34;&gt;Experiment Design&lt;/h1&gt;
&lt;h2 id=&#34;metric-choice&#34;&gt;Metric Choice&lt;/h2&gt;
&lt;p&gt;First, we need to pick &lt;strong&gt;Invariant metrics&lt;/strong&gt;. Invariant metrics are the ones used for sanity checks and will remain stable throughout the experiment. In our case,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Number of cookies&lt;/strong&gt;: That is, number of unique cookies to view the course overview page.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Number of clicks&lt;/strong&gt;: That is, the number of unique cookies to click the “Start free trial” button (which happens before the free trial screener is a trigger).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Click-through-probability&lt;/strong&gt;: That is, number of unique cookies to click the “Start free trial” button divided by number of unique cookies to view the course overview page.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then, we have to set up &lt;strong&gt;Evaluation Metrics&lt;/strong&gt;. Evaluation metrics are the ones that we care about, the metrics that must be observed for consideration in the decision to launch the experiment. In our experiment, we have&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Gross conversion:&lt;/strong&gt; That is, the number of user-ids to complete checkout and enroll in the free trial divided by the number of unique cookies to click the “Start free trial” button. (dmin= 0.01)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Retention:&lt;/strong&gt; That is, the number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by number of user-ids to complete checkout. (dmin=0.01)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Net conversion:&lt;/strong&gt; That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the “Start free trial” button. (dmin= 0.0075)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;measure-variability&#34;&gt;Measure Variability&lt;/h2&gt;
&lt;p&gt;Before we dive into experiment design, we need to have a sense about the variability of both of the invariant metrics and evaluation metrics. Udacity provided the baseline values for each metric:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./baseline-rate.png&#34; alt=&#34;Image for post&#34;&gt;&lt;/p&gt;
&lt;p&gt;The standard deviation is calculated given a sample size of 5000 cookies visiting the course overview page.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from math import sqrt
n_pageviews=40000
n_clicks=3200
n_enroll=660
ctp=0.08
n_sample=5000

click_through_probability=0.08 #clicks / pageviews
gross_conversion=0.20625 # enroll / click
retention=0.53 # payment / enroll
net_conversion=0.1093125 # payment / click

&amp;quot;&amp;quot;&amp;quot;analytical standard deviation estimate&amp;quot;&amp;quot;&amp;quot;
# gross_conversion
std_gross_conversion=sqrt(gross_conversion*(1-gross_conversion)/(n_clicks/n_pageviews*n_sample))
# retention
std_retention=sqrt(retention*(1-retention)/(n_enroll/n_pageviews*n_sample))
# net_conversion
std_net_conversion=sqrt(net_conversion*(1-net_conversion)/(n_clicks/n_pageviews*n_sample))
print(&amp;quot;SD of gross conversion(clicks): {:.4} &amp;quot;.format(std_gross_conversion))
print(&amp;quot;SD of Retention(enroll): {:.4} &amp;quot;.format(std_retention))
print(&amp;quot;SD of Net Conversion(clicks): {:.4}&amp;quot;.format(std_net_conversion))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-plain&#34;&gt;SD of gross conversion(clicks): 0.02023 
SD of Retention(enroll): 0.05495 
SD of Net Conversion(clicks): 0.0156
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;determine-the-sample-size&#34;&gt;Determine the sample size&lt;/h2&gt;
&lt;p&gt;It is very important to figure out the sample size in order to achieve enough statistical significance and power in our analysis based on our assumptions and goals. In our cases, we choose $\alpha$ = 0.05 and $\beta$ = 0.2 to calculate the sample size for the selected evaluation metrics. There are two approaches to determine the experiment sample size &lt;a href=&#34;https://www.kaggle.com/mariusmesserschmied/udacity-a-b-testing-final-course-project&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learned from here&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Approach A:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If we assume that the standard deviations of the population proportion and the sample proportion are equal and that also the sample sizes of treatment and control group are the same, then the required experiment sample size per group can be determined through (as outlined &lt;a href=&#34;http://vanbelle.org/chapters%5cwebchapter2.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;$$n=2(z_{1−α/2}+z_{1−β})^2∗ \frac{σ^2}{d_{min}^2}$$&lt;/p&gt;
&lt;p&gt;with $σ=SE * \sqrt{n}$ ,whereby here n is the sample size we used to calculate SE earlier.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Approach B:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If we do not assume common standard deviations then a more precise way to determine the required sample size would be (as outlined &lt;a href=&#34;http://vanbelle.org/chapters%5cwebchapter2.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;). This is also the approach used by many online sample size calculators such as the one by &lt;a href=&#34;https://www.evanmiller.org/ab-testing/sample-size.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Evan Miller &lt;/a&gt;and we will apply it in the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def get_sampleSize (alpha, beta, p, dmin):
    &#39;&#39;&#39;Return sample size given alpha, beta, p and dmin&#39;&#39;&#39;
    return (pow((stats.norm.ppf(1-alpha/2)*(2*p*(1-p))**0.5+stats.norm.ppf(1-beta)*(p*(1-p)+(p+dmin)*(1-(p+dmin)))**0.5),2))/(pow(dmin,2))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(get_sampleSize(0.05, 0.2, gross_conversion, 0.01))
print(get_sampleSize(0.05, 0.2, retention, 0.01))
print(get_sampleSize(0.05, 0.2, net_conversion, 0.0075))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the result:&lt;/p&gt;
&lt;p&gt;Clicks for Gross Conversion = 25835&lt;/p&gt;
&lt;p&gt;Clicks for Retention = 39115&lt;/p&gt;
&lt;p&gt;Clicks for Net Conversion = 27413&lt;/p&gt;
&lt;p&gt;Because we are having two groups, control and experiment groups in our experiment, therefore the pageview required for each metric are:&lt;/p&gt;
&lt;p&gt;Gross Conversion = (28835*2)/0.08 = 645875&lt;/p&gt;
&lt;p&gt;Retention = (39115*2)/(660/40000) = 4741212&lt;/p&gt;
&lt;p&gt;Net Conversion = (27413*2)/0.08 = 685325&lt;/p&gt;
&lt;p&gt;If we want to test out all of the three metrics, the sample size for the number of pageviews is the maximum 4741212.&lt;/p&gt;
&lt;h2 id=&#34;choosing-experiment-duration-and-exposure&#34;&gt;Choosing experiment duration and exposure&lt;/h2&gt;
&lt;p&gt;Some Udacity questions on this part is as follows:  What percentage of Udacity’s traffic would you divert to this experiment (assuming there were no other experiments you wanted to run simultaneously)? Is the change risky enough that you wouldn’t want to run on all traffic?&lt;/p&gt;
&lt;p&gt;Given the percentage you chose, how long would the experiment take to run, using the analytic estimates of variance? If the answer is longer than a few weeks, then this is unreasonably long, and you should reconsider an earlier decision.&lt;/p&gt;
&lt;p&gt;Based on the description of the project, this feature change is not risky in term of the content and the ways for students accessing the content. It simply add one more question before the student accessing the course materials. Therefore, probably we can run on all the traffic if necessary.&lt;/p&gt;
&lt;p&gt;Based on the sample size we need for each metrics, we need 4741212 pageviews in total, and it take around 119 days to run the experiment if we divert all the pageviews given 40000 pageviews a day. Apparently, the experiment takes too long and costly, so we should reconsider the decision about the metric we choose. We can choose the second largest sample size, 685325, to test out Gross Conversion and Net Conversion. In this case, it takes 17 days if we use all of the traffic or it takes 21 days if we use 80% of the traffic.&lt;/p&gt;
&lt;h1 id=&#34;experiment-analysis&#34;&gt;Experiment Analysis&lt;/h1&gt;
&lt;h2 id=&#34;sanity-check&#34;&gt;Sanity Check&lt;/h2&gt;
&lt;p&gt;In our experiment, we need to make sure some invariant metrics stay the same throughout the experiment, and this is one of the ways to make sure our experiment is executed as we designed and expected. We expect that the total number of pageviews in the control group and the experiment group each account for 50% of the total number of pageviews diverted by cookies.&lt;/p&gt;
&lt;p&gt;The first step of the sanity check for pageviews and clicks is to calculate the probability for the control group and the experiment group.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# pageviews
sum_pv_cont= df[&#39;pageviews_control&#39;].sum()
sum_pv_exp= df[&#39;pageviews_exp&#39;].sum()
SD_pageviews= sqrt(0.5*0.5/(sum_pv_cont+sum_pv_exp))
m=1.96*SD_pageviews
ci_lower,ci_upper=0.5-m,0.5+m
print(&amp;quot;Confidence Interval for pageviews: [{:.4},{:.4}]&amp;quot;.format(ci_lower,ci_upper))
print(&amp;quot;Observed: {:.4}&amp;quot;.format(sum_pv_cont/(sum_pv_exp+sum_pv_cont)))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;u&gt;(check out more code in the following attachment)&lt;/u&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Pageviews&lt;/th&gt;
&lt;th&gt;Clicks&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Probability = # Control / # Total&lt;/td&gt;
&lt;td&gt;0.5006&lt;/td&gt;
&lt;td&gt;0.5005&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Standard Error = 1.96*SE ($\alpha$=0.05)&lt;/td&gt;
&lt;td&gt;0.0006&lt;/td&gt;
&lt;td&gt;0.0041&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lower bound&lt;/td&gt;
&lt;td&gt;0.4988&lt;/td&gt;
&lt;td&gt;0.4959&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Upper bound&lt;/td&gt;
&lt;td&gt;0.5012&lt;/td&gt;
&lt;td&gt;0.5041&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Significance&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Since the probability for both Pageviews and Click falls within the confidence interval calculated from the binomial distribution, we believe that these two invariant metrics pass the sanity check.&lt;/p&gt;
&lt;p&gt;From Click Through probability, we expect that the difference between two groups be zero, so we will use pooled statistics to do the sanity check.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Click Through Probability&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;$\hat{d}$&lt;/td&gt;
&lt;td&gt;0.00005&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SE_Pool_p&lt;/td&gt;
&lt;td&gt;0.00066&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lower bound&lt;/td&gt;
&lt;td&gt;-0.00129&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Upper bound&lt;/td&gt;
&lt;td&gt;0.00129&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Since the observed different $\hat{d}$ falls in the confidence interval, the Click Through Probability passes the sanity test.&lt;/p&gt;
&lt;h2 id=&#34;effect-size-tests&#34;&gt;Effect size tests&lt;/h2&gt;
&lt;p&gt;The focus here is to find out whether our evaluation metrics are statistically and practically significant. It can be achieved by calculating the confidence interval for the difference between the control and experiment groups.&lt;/p&gt;
&lt;p&gt;Just a quick recap: A metric is &lt;strong&gt;statistically significant&lt;/strong&gt; if the confidence interval does not include 0 (that is, you can be confident there was a change), and it is &lt;strong&gt;practically significant&lt;/strong&gt; if the confidence interval does not include the practical thresholds we set at the beginning (that is, you can be confident there is a change that matters to the business.)&lt;/p&gt;
&lt;p&gt;With the power of the size of the sample we have, we can evaluate the Gross Conversion and Net Conversion for our last piece.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Gross Conversion&lt;/th&gt;
&lt;th&gt;Net Conversion&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;dmin&lt;/td&gt;
&lt;td&gt;0.01&lt;/td&gt;
&lt;td&gt;0.0075&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Observed Difference&lt;/td&gt;
&lt;td&gt;-0.0205&lt;/td&gt;
&lt;td&gt;-0.0048&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CI lower bound&lt;/td&gt;
&lt;td&gt;-0.0291&lt;/td&gt;
&lt;td&gt;-0.0116&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CI upper bound&lt;/td&gt;
&lt;td&gt;-0.012&lt;/td&gt;
&lt;td&gt;0.019&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Statistically significance&lt;/td&gt;
&lt;td&gt;True&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Practically significance&lt;/td&gt;
&lt;td&gt;True&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For Net Conversion, the difference between control and experiment groups is insignificant. The confidence interval include both 0 and negative dmin. For Gross Conversion, the confidence interval does not include 0 or practical significance, therefore it is both statistically and practically significant.&lt;/p&gt;
&lt;h2 id=&#34;sign-test&#34;&gt;Sign test&lt;/h2&gt;
&lt;p&gt;The sign test is to check whether the signs of the difference of the metrics between the experiment and control groups agree with the confidence interval of the difference. The p-value indicates the likelihood that the result of the signs is happen by chance using binomial distribution.&lt;/p&gt;
&lt;p&gt;As our code indicates, Gross Conversion has a statistically significant result from the sign test, and Net conversion does not have the same result.&lt;/p&gt;
&lt;h1 id=&#34;recommendation&#34;&gt;Recommendation&lt;/h1&gt;
&lt;p&gt;The goal of this experiment is designed to understand whether the screen will filter the students who cannot commit themselves to finish the courses at the end, and thus help to reduce the number of students who left the free trial, while not reducing the number of students who will make the payment after completing their free trial. Our experiment show that Gross Conversion will be reduced significantly, and the Net Conversion rate has no significant change. Therefore, the screener will help to reduce the students who start the free trial, but there is not enough evidence to show that there will be more students who make the payments and continue their courses. Thus, I would not recommend Launching this screener.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;See implementation&lt;/strong&gt;(&lt;a href=&#34;./a-b-testing-python-implement-final-project.ipynb&#34;&gt;code&lt;/a&gt;, &lt;a href=&#34;./a-b-testing-python-implement-final-project.html&#34;&gt;html&lt;/a&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Malaria Cell Image Detection</title>
      <link>https://ruilong96.github.io/project/malaria_cell_image_detection/</link>
      <pubDate>Fri, 13 Nov 2020 16:35:20 -0500</pubDate>
      <guid>https://ruilong96.github.io/project/malaria_cell_image_detection/</guid>
      <description>&lt;h1 id=&#34;about-the-project&#34;&gt;About the project&lt;/h1&gt;
&lt;p&gt;The main goal of this project is to detect the infected Malaria cells among the images of the parasitized and uninfected cells.&lt;/p&gt;
&lt;h1 id=&#34;methodology&#34;&gt;Methodology&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Data: The dataset is acquired from Kaggle dataset a total of 27,558 cell images with equal instances of parasitized and uninfected cells, which are segmented cells from the thin blood smear slide images from the Malaria Screener research activity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Metadata: The images are stored in two folders labelled as infected and uninfected. Each of images is in RGB format and has size of 142 × 163 pixels.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Since the dataset contains a set of image data and the project is a classification problem, I consider that convolution neural network(CNN) is the most reasonable and appropriate approach for this project. Also, it is because CNNs work well with data that has a spatial relationship.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Metrics: Tuned and evaluated models through computing the accuracy, presented by confusion matrix and accuracy score on the test set.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;result-summary&#34;&gt;Result summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Baseline model:
&lt;ul&gt;
&lt;li&gt;94.4% accuracy on the test set&lt;/li&gt;
&lt;li&gt;Precision = 0.9408122833085686&lt;/li&gt;
&lt;li&gt;Recall = 0.9200775006054734&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;./ROC1.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Regularized model:
&lt;ul&gt;
&lt;li&gt;95.8% accuracy on the test set&lt;/li&gt;
&lt;li&gt;Precision = 0.9501204819277108&lt;/li&gt;
&lt;li&gt;Recall = 0.9661847586375888&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;./ROC2.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Model using Keras:
&lt;ul&gt;
&lt;li&gt;95.27% accuracy on the test set&lt;/li&gt;
&lt;li&gt;Precision = 0.925703737886479&lt;/li&gt;
&lt;li&gt;Recall = 0.9830923793187945&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;./ROC3.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;further-details&#34;&gt;Further Details&lt;/h1&gt;
&lt;p&gt;For more information, check out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;./malaria-cell-project-report.pdf&#34;&gt;Project Report&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Project Code (&lt;a href=&#34;./malaria-cell-detection-using-tensorflow.html&#34;&gt;html&lt;/a&gt; or &lt;a href=&#34;&#34;&gt;github&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Data visualization using Tableau #makeOverMonday</title>
      <link>https://ruilong96.github.io/project/make-over-monday/</link>
      <pubDate>Tue, 10 Nov 2020 15:23:43 -0500</pubDate>
      <guid>https://ruilong96.github.io/project/make-over-monday/</guid>
      <description>&lt;div class=&#39;tableauPlaceholder&#39; id=&#39;viz1605903549902&#39; style=&#39;position: relative&#39;&gt;&lt;noscript&gt;&lt;a href=&#39;#&#39;&gt;&lt;img alt=&#39; &#39; src=&#39;https:&amp;#47;&amp;#47;public.tableau.com&amp;#47;static&amp;#47;images&amp;#47;Ni&amp;#47;NintendoSwitchSales_16051607122020&amp;#47;Dashboard2&amp;#47;1_rss.png&#39; style=&#39;border: none&#39; /&gt;&lt;/a&gt;&lt;/noscript&gt;&lt;object class=&#39;tableauViz&#39;  style=&#39;display:none;&#39;&gt;&lt;param name=&#39;host_url&#39; value=&#39;https%3A%2F%2Fpublic.tableau.com%2F&#39; /&gt; &lt;param name=&#39;embed_code_version&#39; value=&#39;3&#39; /&gt; &lt;param name=&#39;site_root&#39; value=&#39;&#39; /&gt;&lt;param name=&#39;name&#39; value=&#39;NintendoSwitchSales_16051607122020&amp;#47;Dashboard2&#39; /&gt;&lt;param name=&#39;tabs&#39; value=&#39;no&#39; /&gt;&lt;param name=&#39;toolbar&#39; value=&#39;yes&#39; /&gt;&lt;param name=&#39;static_image&#39; value=&#39;https:&amp;#47;&amp;#47;public.tableau.com&amp;#47;static&amp;#47;images&amp;#47;Ni&amp;#47;NintendoSwitchSales_16051607122020&amp;#47;Dashboard2&amp;#47;1.png&#39; /&gt; &lt;param name=&#39;animate_transition&#39; value=&#39;yes&#39; /&gt;&lt;param name=&#39;display_static_image&#39; value=&#39;yes&#39; /&gt;&lt;param name=&#39;display_spinner&#39; value=&#39;yes&#39; /&gt;&lt;param name=&#39;display_overlay&#39; value=&#39;yes&#39; /&gt;&lt;param name=&#39;display_count&#39; value=&#39;yes&#39; /&gt;&lt;param name=&#39;language&#39; value=&#39;en&#39; /&gt;&lt;/object&gt;&lt;/div&gt;                &lt;script type=&#39;text/javascript&#39;&gt;                    var divElement = document.getElementById(&#39;viz1605903549902&#39;);                    var vizElement = divElement.getElementsByTagName(&#39;object&#39;)[0];                    if ( divElement.offsetWidth &gt; 800 ) { vizElement.style.width=&#39;1366px&#39;;vizElement.style.height=&#39;1293px&#39;;} else if ( divElement.offsetWidth &gt; 500 ) { vizElement.style.width=&#39;1366px&#39;;vizElement.style.height=&#39;1293px&#39;;} else { vizElement.style.width=&#39;100%&#39;;vizElement.style.height=&#39;727px&#39;;}                     var scriptElement = document.createElement(&#39;script&#39;);                    scriptElement.src = &#39;https://public.tableau.com/javascripts/api/viz_v1.js&#39;;                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                &lt;/script&gt;</description>
    </item>
    
    <item>
      <title>Airbnb Price Analysis and Visualization</title>
      <link>https://ruilong96.github.io/project/airbnb-baseline/</link>
      <pubDate>Tue, 20 Nov 2018 18:17:32 -0500</pubDate>
      <guid>https://ruilong96.github.io/project/airbnb-baseline/</guid>
      <description>&lt;h1 id=&#34;about-the-project&#34;&gt;About the project&lt;/h1&gt;
&lt;p&gt;The main goal of this project is to analyze the Airbnb listing in the Los Angeles area, provide visualization and some baseline strategy based on the EDA&lt;/p&gt;
&lt;h1 id=&#34;methodology&#34;&gt;Methodology&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The data we used is collected by &lt;a href=&#34;http://insideairbnb.com/get-the-data.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Inside Airbnb&lt;/a&gt;, an open source database that allows people to explore how Airbnb is really being used in cities around the world. Within lots of cities in the database, we focus solely on the Los Angeles area dataset. The data is scraped from the Airbnb website once every month, and normally is on the first Monday of each month. The available data for listings in NYC is ranging from 01 January, 2015 till now. For each of the monthly data, the dataset contains five files as the following&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;listings.csv.gz:&lt;/strong&gt; Detailed Listings data for the Los Angeles area&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Calendar.csv.gz:&lt;/strong&gt; Detailed Calendar Data for listings captured on the scarped day&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reviews.csv.gz:&lt;/strong&gt; Detailed Review Data for listings&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Listings.csv:&lt;/strong&gt; summary information and metrics for listings&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reviews.csv:&lt;/strong&gt; summary review data and Listing ID&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use folim to perform cluster analysis and visualization. The interactive map can be a baseline tool for host to understand the average price in its area&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use plotly to reveal the trend and the density of new listings on Airbnb in each of the areas.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;takeaways&#34;&gt;Takeaways&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;./map4.gif&#34; alt=&#34;map4&#34;&gt;&lt;img src=&#34;./map1.PNG&#34; alt=&#34;map1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./map3.PNG&#34; alt=&#34;map3&#34;&gt;&lt;img src=&#34;./map2.PNG&#34; alt=&#34;map3&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Popular areas such as Santa Monica Beach, Beverly Hill are more expensive then the other areas.&lt;/li&gt;
&lt;li&gt;Los Angeles downtown is densely populated by the listings in the recent years, but the price are not as expensive as the other area.&lt;/li&gt;
&lt;li&gt;Roland heights area has more listings in the recent years with a relatively low price compared to the other area&lt;/li&gt;
&lt;li&gt;The listings to the north where is closed to Angeles National Forest is relatively expensive but is less supplied. We would recommend that the host in these areas add more listings.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
